{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i2.wp.com/hackwagon.com/wp-content/uploads/2017/02/Logo-Web-Export.png?ssl=1\" width=200/></center>\n",
    "<h1> Hackwagon Academy DS102 Lesson 1B </h1>\n",
    "<h2> Pandas (Part 1)</h2> \n",
    "<h3> Lesson Outline </h3>\n",
    "\n",
    "- [Pandas](#Pandas)\n",
    "- 1. [Series & DataFrame](#1)\n",
    "    - 1.1 [Series](#1.1)\n",
    "        - 1.1.1 [Creation](#1.1.1)\n",
    "        - 1.1.2 [Indexing/Selection](#1.1.2)\n",
    "    - 1.2 [DataFrame](#1.2)\n",
    "        - 1.2.1 [Creation](#1.2.1)\n",
    "        - 1.2.2 [Indexing/Selection](#1.2.2)\n",
    "    - 1.3 [Manipulation](#1.3)\n",
    "        - 1.3.1 [Mathematical](#1.3.1)\n",
    "        - 1.3.2 [New/Renew Columns](#1.3.2)\n",
    "        - 1.3.3 [Sorting](#1.3.3)\n",
    "    - 1.4 [Descriptive Statistics](#1.4)\n",
    "- 2. [Merging Datasets](#2)\n",
    "    - 2.1 [.concat()](#2.1)\n",
    "    - [Practice I](#P1)\n",
    "- 3. [Filtering](#3)\n",
    "    - 3.1 [Boolean Array](#3.1)\n",
    "    - 3.2 [.isin()](#3.2)\n",
    "    - [Practice II](#P2)\n",
    "- 4. [Data Cleaning - Handling Missing Values](#4)\n",
    "    - 4.1 [.isnull()](#4.1)\n",
    "    - 4.2 [.dropna()](#4.2)\n",
    "    - 4.3 [.fillna()](#4.3)\n",
    "    - [Practice III](#P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "<a id='1'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;</font><font color=\"salmon\"> Pandas </font> </h2></a>\n",
    "\n",
    "Pandas is an enhanced version of the NumPy structured arrays in which the rows and columns are identified with labels, rather than simple integer indices. As such Pandas can be summarised in the following manner:\n",
    "\n",
    "<img src=\"https://i.imgur.com/39x4BDw.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='1'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;1.</font><font color=\"salmon\"> Series & DataFrame </font> </h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'><h3>1.1 Series</h3></a>\n",
    "\n",
    "The Pandas Series is a one-dimensional array of indexed data. It can be created from a list or array. Think of them like a more versatile versions of lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1.1'><h3>1.1.1 Creation</h3></a>\n",
    "\n",
    "### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [10, 20, 30]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_counts = {\"Apple\": 10, \n",
    "                \"Banana\": 20, \n",
    "                \"Cherries\": 30}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1.2'><h3>1.1.2 Indexing/Selecting</h3></a>\n",
    "\n",
    "Just select accessing a list, you can use the `[]` to access base on its index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'><h3>1.2 DataFrame</h3></a>\n",
    "\n",
    "Think of DataFrames like overpowered Dictionaries with many powerful functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2.1'><h3>1.2.1 Creation</h3></a>\n",
    "\n",
    "### Python Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    # column 1       column 2   column 3\n",
    "    {'name': 'Alex', 'age': 20, 'salary': 1050},  #row 1\n",
    "    {'name': 'Bob', 'age': 52, 'salary': 1400}, #row 2\n",
    "    {'name': 'Cat', 'age': 23, 'salary': 1690} #row 3\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "To manipulate data as a `DataFrame`, use `pd.read_csv()` to read the CSV file into a `DataFrame`. Refer to the documentation [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv). For the next few examples, we will be using the `HWAPandasSandbox.csv` dataset, as `feedback_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2.2'><h3>1.2.2 Indexing/Selecting</h3></a>\n",
    "\n",
    "DataFrames are many Series stacked on top of another. Again, similar to how you use keys in dictionaries, you can just select the columns by their names (case sensitive).\n",
    "\n",
    "#### One Column\n",
    "\n",
    "By acccessing just one column/row, you get a <b>Series</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Columns\n",
    "\n",
    "By acccessing just more than one column/row, you get a <b>DataFrame</b>.\n",
    "\n",
    "To select multiple columns, use a list instead which also allows you to reorganise the column orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = ['ClassType', 'Instructor', 'Coordinating_TA']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row Wise Selection\n",
    "\n",
    "To select row wise, use `.iloc[]` meaning Integer Locate where it selects by the row number (index).\n",
    "\n",
    "If you want to select by a non numeric index, use `.loc[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'><h3>1.3 Manipulation</h3></a>\n",
    "\n",
    "Similar to how Numpy arrays can be manipulated for different results, DataFrames can also be manipulated in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3.1'><h3>1.3.1 Mathematical</h3></a>\n",
    "\n",
    "Since Pandas is built to integrate with Numpy, you can notice the similiarities here. We can extract a Series and use mathematical operators on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More than one column\n",
    "\n",
    "We can use two or more columns to do mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3.2'><h3>1.3.2 Creating New/Renewing Columns</h3></a>\n",
    "\n",
    "We can also create new columns to the DataFrame.\n",
    "\n",
    "```python\n",
    "    dataframe_to_update['new column name'] = new_series\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3.3'><h3>1.3.3 Sorting</h3></a>\n",
    "\n",
    "We can also sort by a particular column using the `.sort_values()`. Inside this method, the `by=` argument allows you to pick the column(s) you want to sort by; the `ascending=` argument allows you to choose whether to have it in ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'><h3>1.4 Descriptive Statistics</h3></a>\n",
    "\n",
    "`Dataframes` and `Series` objects have many useful methods to help you compute statistics.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Statistical measure</th>\n",
    "    <th>Dataframe method</th>\n",
    "    <th>Series method</th>\n",
    "    <th>Description</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mean</td>\n",
    "    <td>df.mean()</td>\n",
    "    <td>df['column_name'].mean()</td>\n",
    "    <td>Returns the mean of all columns / the selected column</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Median</td>\n",
    "    <td>df.median()</td>\n",
    "    <td>df['column_name'].median()</td>\n",
    "    <td>Returns the median of all columns / the selected column</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Standard Deviation</td>\n",
    "    <td>df.std()</td>\n",
    "    <td>df['column_name'].std()</td>\n",
    "    <td>Returns the standard deviation of all columns / the selected column</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Sum</td>\n",
    "    <td>df.sum()</td>\n",
    "    <td>df['column_name'].std()</td>\n",
    "    <td>Returns the sum of all columns / the selected column</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "The `.describe()` is able to provide the five-number-summary of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;2.</font><font color=\"salmon\"> Merging Datasets </font> </h2></a>\n",
    "\n",
    "During the course of DS102, you might want to merge several datasets together in order to make your analysis more wellrounded. Pandas provides you with methods to merge datasets together. One of the most common ways is `.concat()`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'><h3>2.1 <code>.concat()</code></h3></a>\n",
    "\n",
    "By using concat, we can merge two dataframes together to give us a bigger dataframe, using `pd.concat()`.\n",
    "\n",
    "```python\n",
    "    pd.concat([df1, df2 ...])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_1 = pd.read_csv('HWAPandasSandbox.csv')\n",
    "feedback_2 = pd.read_csv('HWAPandasSandbox.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P1'><h2> <img src=\"https://cdn.shopify.com/s/files/1/1200/7374/products/book_aec28e76-52ec-44ab-bc01-41df1279c89f_550x825.png?v=1473897430\" width=25 align=\"left\"> <font color=\"darkorange\"> &nbsp; Practice I </font><font color=\"skyblue\"> * </font></h2></a>\n",
    "\n",
    "### Wines Dataset\n",
    "\n",
    "### Question 1 - Merge the two datasets and preview dataset\n",
    "\n",
    "Read the dataset from `wines-1.csv` and `wines-2.csv` into `wines_1_df` and `wines_2_df` respective. Specify the `sep` parameter as the separator right now is no longer a comma.\n",
    "\n",
    "Combine the two Dataframes as `all_wines_df` and preview it with `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 2 - Create a new column that doubles the `points `\n",
    "\n",
    "Create a new column called `doubled_points` which multiplies the `points` column by 2.\n",
    "\n",
    "<b>Expected Output:</b>\n",
    "\n",
    "<img src=\"https://i.imgur.com/us7oqHV.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 3 - Create a new column that converts the `price` to SGD \n",
    "\n",
    "Given SGD to USD conversion is 1 USD is 1.39 SGD, called `SGD($)`\n",
    "\n",
    "<b>Expected Output:</b>\n",
    "\n",
    "<img src=\"https://i.imgur.com/nfOPpdV.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 4 - Get the summary statistics of the `price` column\n",
    "\n",
    "<b>Expected Output:</b>\n",
    "\n",
    "    count    2718.000000\n",
    "    mean       32.773731\n",
    "    std        31.288298\n",
    "    min         5.000000\n",
    "    25%        16.000000\n",
    "    50%        24.000000\n",
    "    75%        40.000000\n",
    "    max       500.000000\n",
    "    Name: price, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 5 - Shift Columns\n",
    "\n",
    "Shift the columns of the dataframe to the following:\n",
    "\n",
    "<b>Expected Output:</b>\n",
    "\n",
    "<img src=\"https://i.imgur.com/Egl9aQn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;3.</font><font color=\"salmon\"> Filtering </font> </h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.1'><h3>3.1 Boolean Array</h3></a>\n",
    "\n",
    "\n",
    "We can filter for results within a `DataFrame` to get the data we want. \n",
    "\n",
    "We specify the column we want to isolate in the DataFrame, then specify the boolean condition we are looking for. For example, we want to find the `Females` in the `Sex` column. \n",
    "\n",
    "```python\n",
    "df['sex'] == 'Females'\n",
    "\n",
    "# or for multiple conditions, we link them by & (and) or | (or) symbols\n",
    "# where each condition is surrounded by a ()\n",
    "\n",
    "(df['sex'] == 'Females') & (df['type_of_course'] == 'Medicine')\n",
    "\n",
    "```\n",
    "\n",
    "This gives us a Boolean array of multiple `True` and `False` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Boolean Arrays to Filter\n",
    "By creating many of these Boolean Array allow you to stack them too as shown above\n",
    "\n",
    "<b>Note the square brackets</b>\n",
    "\n",
    "```python\n",
    "   \n",
    "    dataframe[<boolean array here> & <boolean array here>] \n",
    "\n",
    "```\n",
    "\n",
    "We put this Boolean Series inside another `[]` to take out the data within the DataFrame. What this does is it only extracts the rows with the `True` value within the DataFrame. For example,\n",
    "\n",
    "```python\n",
    "df[df['sex'] == 'Females']\n",
    "\n",
    "```\n",
    "<div class=\"alert alert-success\">\n",
    "<b> It is important to note that this does not permanently alter or change the original DataFrame in any way. As \n",
    "such, all filtered data should be stored into another variable.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = feedback_df['ClassType'] ==  \"DS101\"\n",
    "cond2 = feedback_df['Instructor'] ==  \"Andre\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employees Dataset\n",
    "\n",
    "Read the `employees-1k.csv` as `employees_df` and preview the dataset with `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df = pd.read_csv('employees-1k.csv')\n",
    "\n",
    "employees_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.2'><h3>3.2 <code>.isin()</code></h3></a>\n",
    "\n",
    "`.isin()` allows you to search for multiple values within a single column, instead of using a very long conditional. This method returns a Boolean array too.\n",
    "\n",
    "Take the following as an example, where we're looking for only `OWN` and `RENT` in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cond1 = employees_df['home_ownership'].isin(['OWN', 'RENT'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P2'><h2> <img src=\"https://cdn.shopify.com/s/files/1/1200/7374/products/book_aec28e76-52ec-44ab-bc01-41df1279c89f_550x825.png?v=1473897430\" width=25 align=\"left\"> <font color=\"darkorange\"> &nbsp; Practice II </font><font color=\"skyblue\"> * </font></h2></a>\n",
    "\n",
    "### Question 1 - Get the total `annual_inc` for all employees who `OWN` homes\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "    7156267.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Get the average income for all employees who `OWN` or `RENT` homes who earns an `annual_inc` between 50000 to 100000, both inclusive\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "    68465.2265625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;4.</font><font color=\"salmon\"> Data Cleaning - Handling Missing Data</font> </h2></a>\n",
    "\n",
    "Missing data is a common theme when preprocessing data. There are several ways to handle such scenarios and the choice is up to you to decide. For this section we will be using the Wines Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wines_df = pd.read_csv('wines-3k.csv', sep='|') # sep for separater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'><h3>4.1 <code>.isnull()</code></h3></a>\n",
    "\n",
    "`isnull()` gives a Boolean Array/DataFrame that checks every single value if they are missing or not and returns a DataFrame of all True/False, where True means missing value is present.\n",
    "\n",
    "The `.sum()` adds up all the True / False values, where 1 is True and 0 is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'><h3>4.2 <code>.dropna()</code></h3></a>\n",
    "\n",
    "Sometimes, it is better to drop these missing rows entirely rather than spending the time to understand why it's missing. `.dropna()` allows you to drop these rows/columns. The `axis=` argument allows you to drop column or row wise, 0 or 1.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b> It is important to note that when you drop these rows/columns, the original dataframe doesn't change. It only returns you a new DataFrame with the dropped rows/columns.</b> This will be a recurring theme when you do data transformation.\n",
    "</div>\n",
    "\n",
    "\n",
    "To make sure that the changes is applied to the original dataframe, add the `inplace=` argument and set it as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'><h3>4.3 <code>.fillna()</code></h3></a>\n",
    "\n",
    "However, given this wine dataset, it dropping may not be the best idea too. Since price is a numeric value, we can fill up these values with zero, therefore retaining the rows, not losing out on the data. \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b> It is important to note that when you change these rows/columns, the original dataframe doesn't change. It only returns you a new DataFrame with the changed rows/columns.</b> This will be a recurring theme when you do data transformation.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "To make sure that the changes is applied to the original dataframe, add the `inplace=` argument and set it as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P3'><h2> <img src=\"https://cdn.shopify.com/s/files/1/1200/7374/products/book_aec28e76-52ec-44ab-bc01-41df1279c89f_550x825.png?v=1473897430\" width=25 align=\"left\"> <font color=\"darkorange\"> &nbsp; Practice III </font><font color=\"skyblue\"> * </font></h2></a>\n",
    "\n",
    "### Employees Dataset\n",
    "\n",
    "Read the `employees-1k.csv` dataset as `employees_df` and preview it with `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Find the number of empty values for each column\n",
    "\n",
    "**Expected Output:**\n",
    "    \n",
    "    employee_id        0\n",
    "    annual_inc         0\n",
    "    employee_title    57\n",
    "    home_ownership     0\n",
    "    dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Fill empty values with a \"Not Valid\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
