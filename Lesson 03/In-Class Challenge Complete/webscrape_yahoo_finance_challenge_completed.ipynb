{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Editable": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Webscraping Yahoo Finance\n",
    "## Introduction\n",
    "In this challenge, we will be using what we have learnt in the class to scrape stock information from Yahoo Finance. \n",
    "\n",
    "\n",
    "The following are general steps to scrape websites:\n",
    "1. Identify target website.\n",
    "2. Learn how the website constructs their URL so we can retrieve the desired page from the website.\n",
    "3. Programmatically retrieve websites with the URL we reverse-engineered from the website.\n",
    "4. Use libraries to traverse and obtain information we need from website.\n",
    "5. Organise the information and return in desired format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the libraries we need\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Identify target website\n",
    "\n",
    "Our target website is Yahoo Finance. Our desired information is the stock information available on the website. \n",
    "\n",
    "Before we start scraping, have a look at how a typical stock information page looks like: \n",
    "\n",
    "__[Apple - AAPL](https://finance.yahoo.com/quote/AAPL?p=AAPL)__ : https://finance.yahoo.com/quote/AAPL?p=AAPL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Deconstruct URL\n",
    "\n",
    "We don't want to manually type in the search box and search for stocks we want. Instead, by studying the URL, we can deconstruct them, and by tweaking them, we can get to the page that holds the stock information we want. \n",
    "\n",
    "\n",
    "For example, look at the URL in **Step 1**. The ticker symbol of the Apple is **AAPL**. Notice that **AAPL** repeats twice in the URL. \n",
    "\n",
    "Perhaps, if we replace **AAPL** in the URL with any ticker symbol we want, we can get the stock information for that stock. \n",
    "\n",
    "For example, try __[Google - GOOG](https://finance.yahoo.com/quote/GOOG?p=GOOG)__ : https://finance.yahoo.com/quote/GOOG?p=GOOG\n",
    "\n",
    "\n",
    "With that knowledge, come up with a function that can give you the URL for any stock ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_url(ticker):\n",
    "    # fill in the part here to get the URL for a particular stock\n",
    "    url = \"https://finance.yahoo.com/quote/\" + ticker + \"?p=\" + ticker\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Step 3. Retrieve website\n",
    "\n",
    "Now that we know which URL to go to, we can retrieve the webpage programmatically, using **requests**. \n",
    "\n",
    "To do so, we use a Python Library called **requests**, which we have imported above.\n",
    "\n",
    "After retrieving the webpage, we then pass it to another library, **BeautifulSoup**, a library that will greatly faciliate our webscraping.\n",
    "\n",
    "**Be patient, the site might take some time to retrieve (~60 seconds)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_website_html(url):\n",
    "    # We need to set HTTP headers to \"trick\" Yahoo Finance to think that we are sending the requests from a desktop browser.\n",
    "    # This is because Yahoo Finance does something called device targeting - sending slightly different website content\n",
    "    # to different devices(e.g. mobile vs desktop). \n",
    "    # We base our scraping logic on what we see on the desktop version of the website, therefore, we want to \"trick\" it as such.\n",
    "    headers = {\"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "            \"accept-encoding\": \"gzip, deflate, br\",\n",
    "            \"accept-language\": \"en-GB,en;q=0.9,en-US;q=0.8,ml;q=0.7\",\n",
    "            \"cache-control\": \"max-age=0\",\n",
    "            \"dnt\": \"1\",\n",
    "            \"sec-fetch-dest\": \"document\",\n",
    "            \"sec-fetch-mode\": \"navigate\",\n",
    "            \"sec-fetch-site\": \"none\",\n",
    "            \"sec-fetch-user\": \"?1\",\n",
    "            \"upgrade-insecure-requests\": \"1\",\n",
    "            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36\"}\n",
    "    # Use Requests and BeautifulSoup to get the website HTML content using requests and BeautifulSoup\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    parsed_html = BeautifulSoup(resp.text, 'html.parser')\n",
    "    return parsed_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Retrieve desired information\n",
    "\n",
    "This step is probably the hardest step. \n",
    "\n",
    "We need to look at our a website is constructed, and utilise bits of the metadata to reliably retrieve the information we need.\n",
    "\n",
    "\n",
    "### Chrome Developer Tool\n",
    "To do so, we can open the **Chrome Developer Tools**. \n",
    "\n",
    "On the Yahoo Finance page, \n",
    "1. hover the mouse over any element you would like to find out more information about,\n",
    "2. Right-click on it.\n",
    "3. Then select inspect.\n",
    "\n",
    "A side bar should popup with the raw HTML information. As you hover your mouse over the HTML elements, it should highlight the location of the element on the page. \n",
    "\n",
    "\n",
    "\n",
    "### Example\n",
    "In the code below, we use the `find` method to look for a HTML element with *tag* `span` and *class* `Fz(36px)`. \n",
    "\n",
    "We then retrieve the textual information nested inside this element with `getText()`.\n",
    "\n",
    "\n",
    "\n",
    "### Your turn!\n",
    "Now, try to identify and scrape more financial data.\n",
    "\n",
    "Here's a list for you to try:\n",
    "1. PE Ratio (TTM)\n",
    "2. EPS (TTM)\n",
    "3. Earnings Date\n",
    "4. Market Cap\n",
    "\n",
    "#### Expected Output for ticker, AAPL:\n",
    "<code>\n",
    "    {\n",
    "        'stock_ticker': 'AAPL,\n",
    "        'price': 317.94,\n",
    "        'pe_ratio': 24.98,\n",
    "        'market_cap': '1.378T',\n",
    "        'eps': 11.89\n",
    "    }\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_information(ticker, website_html):    \n",
    "######## Add in your webscrapping code here to scrape more information #############\n",
    "    \n",
    "####################################################################################\n",
    "######## Remember to add the information to the summary_data object below ##########\n",
    "    price = website_html.find(\"span\", attrs={\"class\": \"Fz(36px)\"}).getText()\n",
    "    pe_ratio = website_html.find(\"span\", attrs={\"data-reactid\": \"149\"}).getText()\n",
    "    market_cap = website_html.find(\"span\", attrs={\"data-reactid\": \"139\"}).getText()\n",
    "    eps = website_html.find(\"span\", attrs={\"data-reactid\": \"154\"}).getText()\n",
    "    summary_data = {\n",
    "        'ticker': ticker,\n",
    "        \"price\": price,\n",
    "        \"pe_ratio\": pe_ratio,\n",
    "        \"market_cap\": market_cap,\n",
    "        \"eps\": eps\n",
    "    }\n",
    "    return summary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "The method below puts everything together.\n",
    "Use the functions you have created above to get the data.\n",
    "1. get_stock_url\n",
    "2. retrieve_website_html\n",
    "3. get_stock_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data(ticker):\n",
    "    \n",
    "    url = get_stock_url(ticker)\n",
    "    print(\"getting from URL: \" + url)\n",
    "    website = retrieve_website_html(url)\n",
    "    summary_data = get_stock_information(ticker, website)\n",
    "    return summary_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use the function you have created to fill in the data\n",
    " Download `stock_list_empty.csv` and use your function to fill in missing data.\n",
    " Remember, you can amend data on a Dataframe using `.loc[row_index, column_name]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from URL: https://finance.yahoo.com/quote/AAPL?p=AAPL\n",
      "getting from URL: https://finance.yahoo.com/quote/GOOG?p=GOOG\n",
      "getting from URL: https://finance.yahoo.com/quote/FB?p=FB\n",
      "getting from URL: https://finance.yahoo.com/quote/AMZN?p=AMZN\n",
      "getting from URL: https://finance.yahoo.com/quote/ZM?p=ZM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_name</th>\n",
       "      <th>stock_ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>pe_ratio</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>eps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>331.50</td>\n",
       "      <td>26.04</td>\n",
       "      <td>1.437T</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>1,438.39</td>\n",
       "      <td>30.87</td>\n",
       "      <td>982.622B</td>\n",
       "      <td>46.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook, Inc.</td>\n",
       "      <td>FB</td>\n",
       "      <td>230.77</td>\n",
       "      <td>36.89</td>\n",
       "      <td>657.487B</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2,483.00</td>\n",
       "      <td>110.02</td>\n",
       "      <td>1.238T</td>\n",
       "      <td>22.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zoom Video Communications, Inc.</td>\n",
       "      <td>ZM</td>\n",
       "      <td>207.60</td>\n",
       "      <td>5,931.43</td>\n",
       "      <td>58.534B</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        stock_name stock_ticker     price  pe_ratio  \\\n",
       "0                       Apple Inc.         AAPL    331.50     26.04   \n",
       "1                    Alphabet Inc.         GOOG  1,438.39     30.87   \n",
       "2                   Facebook, Inc.           FB    230.77     36.89   \n",
       "3                 Amazon.com, Inc.         AMZN  2,483.00    110.02   \n",
       "4  Zoom Video Communications, Inc.           ZM    207.60  5,931.43   \n",
       "\n",
       "  market_cap    eps  \n",
       "0     1.437T  12.73  \n",
       "1   982.622B  46.60  \n",
       "2   657.487B   6.26  \n",
       "3     1.238T  22.57  \n",
       "4    58.534B   0.04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stock_df = pd.read_csv(\"stock_list_empty.csv\")\n",
    "\n",
    "\n",
    "### Use your function below.\n",
    "for idx, stock in stock_df.iterrows():\n",
    "    data = get_ticker_data(stock['stock_ticker'])\n",
    "    stock_df.loc[idx, 'price'] = data['price']\n",
    "    stock_df.loc[idx, 'pe_ratio'] = data['pe_ratio']\n",
    "    stock_df.loc[idx, 'market_cap'] = data['market_cap']\n",
    "    stock_df.loc[idx, 'eps'] = data['eps']\n",
    "    \n",
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
